{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a60527",
   "metadata": {},
   "source": [
    "This is an archive for extracting data with full iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is attemting for exporting dataset--3.0 version\n",
    "\n",
    "import pandas as pd\n",
    "my_scene1=nusc.scene[18]\n",
    "my_scene2=nusc.scene[6]\n",
    "my_scene3=nusc.scene[7]\n",
    "\n",
    "\n",
    "\n",
    "df=pd.DataFrame(columns=['Vehicle', 'Description','Translation','Rotation','Timestamp'])\n",
    "    \n",
    "\n",
    "sensor1='LIDAR_FUSED'\n",
    "sensor2='RADAR_FRONT'\n",
    "sensor3='LIDAR_FRONT'\n",
    "\n",
    " \n",
    "    \n",
    "            \n",
    "for j in [6,7,18]:\n",
    "    \n",
    "    \n",
    "    sample_token = nusc.scene[j]['first_sample_token']\n",
    " \n",
    "    \n",
    "    print(nusc.scene[j])\n",
    "    \n",
    "  \n",
    "    \n",
    " \n",
    "        \n",
    "    \n",
    "\n",
    "    for i in range(nusc.scene[j]['nbr_samples']):\n",
    "    \n",
    "    \n",
    "    \n",
    "        scenes=nusc.scene[j]\n",
    "        log=nusc.get('log',scenes['log_token'])\n",
    "        samples=nusc.get('sample', sample_token)\n",
    "\n",
    "        if j==18:\n",
    "            sample_data=nusc.get('sample_data',samples['data'][sensor3])\n",
    "        else: \n",
    "            try:    \n",
    "                sample_data=nusc.get('sample_data',samples['data'][sensor1])\n",
    "        \n",
    "            except KeyError:\n",
    "           \n",
    "                sample_data=nusc.get('sample_data',samples['data'][sensor2])\n",
    "        \n",
    "       \n",
    "       \n",
    "        ego_pose=nusc.get('ego_pose',sample_data['ego_pose_token'])\n",
    "\n",
    "    \n",
    "        for logs in log:\n",
    "    \n",
    "            log_token=log.get('token')\n",
    "            entry_scenes=[scene for scene in scenes if scenes['log_token']==log_token]\n",
    " \n",
    "            for scene in entry_scenes:\n",
    "        \n",
    "                scene_token=scenes.get('token')\n",
    "                entry_samples = [sample for sample in samples if samples['scene_token'] == scene_token]\n",
    "        \n",
    "        \n",
    "   \n",
    "                for sample in entry_samples:\n",
    "                    vehicle=log.get('vehicle','')\n",
    "                    description=scenes.get('description','')\n",
    "                    timestamp=samples.get('timestamp','')\n",
    "                    sample_token=samples.get('token')\n",
    "            \n",
    "                    entry_sampledata=[sampledata for sampledata in sample_data if sample_data['sample_token']==sample_token]\n",
    "            \n",
    "            \n",
    "            \n",
    "                    for sampledata in entry_sampledata:\n",
    "                \n",
    "                        ego_token=sample_data['ego_pose_token']\n",
    "                        entry_ego=[ego for ego in ego_pose if ego_pose['token']==ego_token]\n",
    "                        for ego in entry_ego:\n",
    "                            translation=ego_pose.get('translation','')\n",
    "                            rotation=ego_pose.get('rotation','')\n",
    "                \n",
    "            \n",
    "           \n",
    "   \n",
    "            \n",
    "        table_row = {'Vehicle': vehicle, 'Description': description,'Translation':translation,'Rotation':rotation,'Timestamp': timestamp}\n",
    "        #print(table_row)\n",
    "        #print(i)\n",
    "        df1 = pd.DataFrame.from_records([table_row])\n",
    "        sample_token=samples['next']\n",
    "               \n",
    "        df=pd.concat([df,df1],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.to_csv('vechile_info.csv',index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd5388a",
   "metadata": {},
   "source": [
    "This is the first prototype of development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is attemting for exporting dataset successfully version 1.0\n",
    "\n",
    "import pandas as pd\n",
    "my_scene1=nusc.scene[18]\n",
    "\n",
    "data = [\n",
    "   {'date_captured': '2022-01-07', 'location': 'LVMS', 'logfile': 'MULTI-FAST-TUM', 'token': '634fc63aa088dc388b2e9a7bdfab5b5b', 'vehicle': 'EURORACING', 'map_token': '7e3b5b651fe150647024ed0a72fe70fe'},\n",
    "  \n",
    "]\n",
    "\n",
    "\n",
    "scenes=[{'description': 'High speed multi-agent laps with TUM', 'first_sample_token': '503ff877b528f907ee7ceb6f24a0dbd2', 'last_sample_token': 'e280475667087aa0695761d84cf4c38a', 'log_token': '634fc63aa088dc388b2e9a7bdfab5b5b', 'name': 'MULTI-FAST-TUM', 'nbr_samples': 1319, 'token': 'b02a9924e4cddd4bbb796e88238fe519'}]\n",
    "# Sample data\n",
    "samples = [\n",
    "   {'next': 'b6da0c68ddb27086665490994b3656e0', 'prev': '', 'scene_token': 'b02a9924e4cddd4bbb796e88238fe519', 'timestamp': 16415847905.03897, 'token': '503ff877b528f907ee7ceb6f24a0dbd2', 'data': {'LIDAR_LEFT': '1f8f6fb4373889dcd07aa7b720943395', 'LIDAR_RIGHT': 'a81b7deedae629cbcde58914c133a7b5', 'LIDAR_FRONT': '4dfc0f23f6df215602ee796534b446e8'}, 'anns': []},\n",
    "\n",
    "    {'next': 'ab1ed4cd7de5e622f37cf61e1eed8b83', 'prev': '503ff877b528f907ee7ceb6f24a0dbd2', 'scene_token': 'b02a9924e4cddd4bbb796e88238fe519', 'timestamp': 16415847910.03897, 'token': 'b6da0c68ddb27086665490994b3656e0', 'data': {'LIDAR_LEFT': '4c8e880186b1a2db62496e4682820e65', 'LIDAR_RIGHT': '3a60a36c7d0419ed3cd99ef08b031005', 'LIDAR_FRONT': 'f0e5423d0211e08c4815dcf5fad0cacb'}, 'anns': []}\n",
    "\n",
    "] \n",
    "\n",
    "sample_data=[{'calibrated_sensor_token': '3e53d76cd4cf5155343bd900db5113a5', 'ego_pose_token': 'f9abfd69de1aa5320519f84d7e8c9d78', 'fileformat': 'pcd.bin', 'filename': '/media/deepracing/eb2709ba-58e9-4fbd-ab00-8aafbd0f9034/NUSCENES_FIXED//samples/LIDAR_FRONT/MULTI-FAST-TUM__LIDAR_FRONT__164158479017587000.pcd.bin', 'height': 0, 'is_key_frame': True, 'next': '13bab4ce827b5512f6b186394b0ce21f', 'prev': '', 'sample_token': '503ff877b528f907ee7ceb6f24a0dbd2', 'timestamp': 1641584790.1758702, 'token': '4dfc0f23f6df215602ee796534b446e8', 'width': 0, 'sensor_modality': 'lidar', 'channel': 'LIDAR_FRONT'},\n",
    "             {'calibrated_sensor_token': '3e53d76cd4cf5155343bd900db5113a5', 'ego_pose_token': '6c67227e66413f12acbd80fe17647a0d', 'fileformat': 'pcd.bin', 'filename': '/media/deepracing/eb2709ba-58e9-4fbd-ab00-8aafbd0f9034/NUSCENES_FIXED//samples/LIDAR_FRONT/MULTI-FAST-TUM__LIDAR_FRONT__1641584791117575000.pcd.bin', 'height': 0, 'is_key_frame': True, 'next': '83d1608f34b089a59af6a5b12fe2eb36', 'prev': '2da9d0d62464d49acad06d1679c0b6fd', 'sample_token': 'b6da0c68ddb27086665490994b3656e0', 'timestamp': 16415847911.175749, 'token': 'f0e5423d0211e08c4815dcf5fad0cacb', 'width': 0, 'sensor_modality': 'lidar', 'channel': 'LIDAR_FRONT'}\n",
    "    \n",
    "]\n",
    "\n",
    "ego_pose=[{'rotation': [0.9686439050309263, 0.0, 0.0, 0.24845318522095436], 'timestamp': 1641584790.49071, 'token': 'f9abfd69de1aa5320519f84d7e8c9d78', 'translation': [-173.65597751189756, 161.84630688088623, 1.8268150982495612]},\n",
    "          {'rotation': [0.9576704904889958, 0.0, 0.0, 0.28786669075557586], 'timestamp': 16415847911.490932, 'token': '6c67227e66413f12acbd80fe17647a0d', 'translation': [-173.59034706177582, 161.73533319597465, 1.826935783472166]}\n",
    "          \n",
    "          \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "df=pd.DataFrame(columns=['Vehicle', 'Description','Translation','Rotation','Timestamp'])\n",
    "    \n",
    "\n",
    "for logs in data:\n",
    "    \n",
    "    log_token=logs.get('token','')\n",
    "    entry_scenes=[scene for scene in scenes if scene['log_token']==log_token]\n",
    " \n",
    "    for scene in entry_scenes:\n",
    "        \n",
    "        scene_token=scene.get('token')\n",
    "        entry_samples = [sample for sample in samples if sample['scene_token'] == scene_token]\n",
    "        \n",
    "        \n",
    "   \n",
    "        for sample in entry_samples:\n",
    "            vehicle=logs.get('vehicle','')\n",
    "            description=scene.get('description','')\n",
    "            timestamp=sample.get('timestamp','')\n",
    "            sample_token=sample.get('token')\n",
    "            \n",
    "            entry_sampledata=[sampledata for sampledata in sample_data if sampledata['sample_token']==sample_token]\n",
    "            \n",
    "            for sampledata in entry_sampledata:\n",
    "                \n",
    "                    ego_token=entry_sampledata[0]['ego_pose_token']\n",
    "                    entry_ego=[ego for ego in ego_pose if ego['token']==ego_token]\n",
    "                    for ego in entry_ego:\n",
    "                            translation=ego.get('translation','')\n",
    "                            rotation=ego.get('rotation','')\n",
    "                \n",
    "            \n",
    "           \n",
    "                \n",
    "        \n",
    "        table_row = {'Vehicle': vehicle, 'Description': description,'Translation':translation,'Rotation':rotation,'Timestamp': timestamp}\n",
    "        print(table_row)\n",
    "               \n",
    "            \n",
    "        df1=pd.DataFrame()\n",
    "        df = pd.concat([df1,pd.DataFrame.from_records([table_row])])\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "df.to_csv('vechile_info.csv',index=False)\n",
    "\n",
    "df\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b914f7",
   "metadata": {},
   "source": [
    "This is the second prototype of development process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acb9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is attemting for exporting dataset successfully version 2.0\n",
    "\n",
    "import pandas as pd\n",
    "my_scene1=nusc.scene[18]\n",
    "\n",
    "\n",
    "\n",
    "df=pd.DataFrame(columns=['Vehicle', 'Description','Translation','Rotation','Timestamp'])\n",
    "    \n",
    "\n",
    "sample_token = my_scene1['first_sample_token']\n",
    "sensor='LIDAR_FRONT'\n",
    "\n",
    " \n",
    "    \n",
    "            \n",
    "            \n",
    "for i in range(my_scene1['nbr_samples']):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data=nusc.get('log',my_scene1['log_token'])\n",
    "    scenes=my_scene1\n",
    "    samples=nusc.get('sample', sample_token)\n",
    "    sample_data=nusc.get('sample_data',samples['data'][sensor])\n",
    "    ego_pose=nusc.get('ego_pose',sample_data['ego_pose_token'])\n",
    "\n",
    "    \n",
    "    for logs in data:\n",
    "    \n",
    "        log_token=data.get('token')\n",
    "        entry_scenes=[scene for scene in scenes if scenes['log_token']==log_token]\n",
    " \n",
    "        for scene in entry_scenes:\n",
    "        \n",
    "            scene_token=scenes.get('token')\n",
    "            entry_samples = [sample for sample in samples if samples['scene_token'] == scene_token]\n",
    "        \n",
    "        \n",
    "   \n",
    "            for sample in entry_samples:\n",
    "                vehicle=data.get('vehicle','')\n",
    "                description=scenes.get('description','')\n",
    "                timestamp=samples.get('timestamp','')\n",
    "                sample_token=samples.get('token')\n",
    "            \n",
    "                entry_sampledata=[sampledata for sampledata in sample_data if sample_data['sample_token']==sample_token]\n",
    "            \n",
    "            \n",
    "            \n",
    "                for sampledata in entry_sampledata:\n",
    "                \n",
    "                    ego_token=sample_data['ego_pose_token']\n",
    "                    entry_ego=[ego for ego in ego_pose if ego_pose['token']==ego_token]\n",
    "                    for ego in entry_ego:\n",
    "                            translation=ego_pose.get('translation','')\n",
    "                            rotation=ego_pose.get('rotation','')\n",
    "                \n",
    "            \n",
    "           \n",
    "   \n",
    "            \n",
    "    table_row = {'Vehicle': vehicle, 'Description': description,'Translation':translation,'Rotation':rotation,'Timestamp': timestamp}\n",
    "    print(table_row)\n",
    "    print(i)\n",
    "    df1 = pd.DataFrame.from_records([table_row])\n",
    "    sample_token=samples['next']\n",
    "               \n",
    "    df=pd.concat([df,df1],ignore_index=True)\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "df.to_csv('vechile_info.csv',index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba8d01",
   "metadata": {},
   "source": [
    "This is one of development process with only 5 times of iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This cell is attemting for exporting dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = [lg]\n",
    "\n",
    "\n",
    "scenes=[my_scene1]\n",
    "first_sample_token = my_scene1['first_sample_token']\n",
    "my_sample = nusc.get('sample', first_sample_token)\n",
    "my_sample\n",
    "\n",
    "# Sample data\n",
    "samples = [my_sample]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=pd.DataFrame(columns=['Vehicle', 'Description','Timestamp'])\n",
    "    \n",
    "\n",
    "for logs in data:\n",
    "    \n",
    "    log_token=logs.get('token','')\n",
    "    entry_scenes=[scene for scene in scenes if scene['log_token']==log_token]\n",
    " \n",
    "    for scene in entry_scenes:\n",
    "        \n",
    "        scene_token=scene.get('token')\n",
    "        entry_samples = [sample for sample in samples if sample['scene_token'] == scene_token]\n",
    "        \n",
    "        \n",
    "   \n",
    "        for sample in entry_samples:\n",
    "            vehicle=logs.get('vehicle','')\n",
    "            description=scene.get('description','')\n",
    "         \n",
    "            \n",
    "            timestamp=sample.get('timestamp','')\n",
    "            \n",
    "\n",
    "            df=df._append({'Vehicle': vehicle, 'Description': description, 'Timestamp': timestamp}, ignore_index=True)\n",
    "        \n",
    "    \n",
    "\n",
    "df.to_csv('vechile_info.csv',index=False)\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#something added later on\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    sample=nusc.get('sample', sample_token)\n",
    "  \n",
    "  \n",
    "  \n",
    "    print('------------',sample)\n",
    "\n",
    "    print('------------',data)\n",
    "    print('------------',pose)\n",
    "\n",
    "    sample_token=sample['next']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59499b45",
   "metadata": {},
   "source": [
    "This is an attempt made by my supervisor during a meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc6d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scene1=nusc.scene[21]\n",
    "print(my_scene1)\n",
    "print('-----')\n",
    "\n",
    "#sample_token = my_scene1['first_sample_token']\n",
    "\n",
    "#print(sample_token)\n",
    "\n",
    "#sample=nusc.get('sample', sample_token)\n",
    "#print(sample)\n",
    "#print('------')\n",
    "\n",
    "#sensor='LIDAR_FRONT'\n",
    "#data=nusc.get('sample_data',sample['data'][sensor])\n",
    "#print(data)\n",
    "#print('------')\n",
    "\n",
    "lg=nusc.get('log',my_scene1['log_token'])\n",
    "print(lg)\n",
    "print('------')\n",
    "\n",
    "\n",
    "\n",
    "#pose=nusc.get('ego_pose',data['ego_pose_token'])\n",
    "#print(pose)\n",
    "#print('------')\n",
    "\n",
    "\n",
    "#sample_token = my_scene1['first_sample_token']\n",
    "#for i in range(5):\n",
    "    #sample=nusc.get('sample', sample_token)\n",
    "    #sample_token=sample['next']\n",
    "    #print(sample)\n",
    "    #print('----')\n",
    "\n",
    "j=0\n",
    "\n",
    "for j in range(21):\n",
    "\n",
    "    my_scene1=nusc.scene[j]\n",
    "    print(my_scene1)\n",
    "    print('------')\n",
    "    lg=nusc.get('log',my_scene1['log_token'])\n",
    "    print(lg)\n",
    "    print('------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16e629",
   "metadata": {},
   "source": [
    "Initial development to list all the samples from scene [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scene2=nusc.scene[10]\n",
    "sample_token = my_scene2['first_sample_token']\n",
    "sensor='LIDAR_FRONT'\n",
    "\n",
    "lg2=nusc.get('log',my_scene2['log_token'])\n",
    "\n",
    "print(lg2)\n",
    "\n",
    "print('The following contents are samples')\n",
    "\n",
    "\n",
    "for i in range(my_scene2['nbr_samples']):\n",
    "\n",
    "    sample2=nusc.get('sample', sample_token)\n",
    "    data2=nusc.get('sample_data',sample2['data'][sensor])\n",
    "    pose2=nusc.get('ego_pose',data['ego_pose_token'])\n",
    "  \n",
    "    print(sample2)\n",
    "    print('------------')\n",
    "    print(data2)\n",
    "    print('------------',i)\n",
    "    print(pose2)\n",
    "\n",
    "    sample_token=sample2['next']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97c5d4",
   "metadata": {},
   "source": [
    "Initial development to list all the samples from scene [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af35edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scene3=nusc.scene[7]\n",
    "sample_token = my_scene3['first_sample_token']\n",
    "sensor='LIDAR_FRONT'\n",
    "\n",
    "lg3=nusc.get('log',my_scene3['log_token'])\n",
    "\n",
    "print(lg3)\n",
    "\n",
    "print('The following contents are samples')\n",
    "\n",
    "\n",
    "for i in range(my_scene3['nbr_samples']):\n",
    "\n",
    "    sample3=nusc.get('sample', sample_token)\n",
    "    data3=nusc.get('sample_data',sample['data'][sensor])\n",
    "    pose3=nusc.get('ego_pose',data['ego_pose_token'])\n",
    "  \n",
    "    print(sample3)\n",
    "    print('------------')\n",
    "    print(data3)\n",
    "    print('------------',i)\n",
    "    print(pose3)\n",
    "\n",
    "    sample_token=sample3['next']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ff1f2",
   "metadata": {},
   "source": [
    "This is a unsuccessful attempt, just for storage purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning task 3\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "\n",
    "df = pd.read_csv('vechile_info.csv')\n",
    "translations = df['Translation'].apply(eval).tolist()\n",
    "rotations = df['Rotation'].apply(eval).tolist()\n",
    "teams = df['Description'].tolist()\n",
    "\n",
    "x_trans = [translation[0] for translation in translations]\n",
    "y_trans = [translation[1] for translation in translations]\n",
    "z_trans = [translation[2] for translation in translations]\n",
    "x_rot = [rotation[0] for rotation in rotations]\n",
    "y_rot = [rotation[1] for rotation in rotations]\n",
    "z_rot = [rotation[2] for rotation in rotations]\n",
    "\n",
    "# Create a 3D plot for Translation\n",
    "fig_trans = plt.figure(figsize=(15, 5 * len(teams)))\n",
    "ax_trans = fig_trans.add_subplot(111, projection='3d')\n",
    "ax_trans.scatter(x_trans, y_trans, z_trans, c='black', marker='o', label='Translation')\n",
    "ax_trans.set_xlabel('Trans1')\n",
    "ax_trans.set_ylabel('Trans2')\n",
    "ax_trans.set_zlabel('Trans3')\n",
    "ax_trans.set_title('Translation Plot')\n",
    "ax_trans.legend()\n",
    "# Create separate 3D plots for each Rotation\n",
    "fig_rot = plt.figure(figsize=(15, 5 * len(teams)))\n",
    "for i, team in enumerate(teams, start=1):\n",
    "    ax_rot = fig_rot.add_subplot(len(teams), 1, i, projection='3d')\n",
    "    indices = [j for j, t in enumerate(teams) if t == team]\n",
    "    ax_rot.scatter([x_rot[j] for j in indices], [y_rot[j] for j in indices], [z_rot[j] for j in indices], c='black', marker='o', label='Rotation')\n",
    "    ax_rot.set_xlabel('Rot1')\n",
    "    ax_rot.set_ylabel('Rot2')\n",
    "    ax_rot.set_zlabel('Rot3')\n",
    "    ax_rot.set_title(f'Rotation Plot for {team}')\n",
    "    ax_rot.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-racecar",
   "language": "python",
   "name": "project-racecar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
